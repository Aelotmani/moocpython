    
    
    
    

    

    \hypertarget{la-data-science-en-guxe9nuxe9ral}{%
\section{La data science en
général}\label{la-data-science-en-guxe9nuxe9ral}}

\hypertarget{et-en-python-en-particulier}{%
\subsection{et en Python en
particulier}\label{et-en-python-en-particulier}}

    \hypertarget{compluxe9ment---niveau-intermuxe9diaire}{%
\subsection{Complément - niveau
intermédiaire}\label{compluxe9ment---niveau-intermuxe9diaire}}

    \hypertarget{quest-ce-quun-data-scientist}{%
\subsubsection{Qu'est-ce qu'un data
scientist~?}\label{quest-ce-quun-data-scientist}}

    J'aimerais commencer cette séquence par quelques réflexions générales
sur ce qu'on appelle data science. Ce mot valise, récemment devenu à la
mode, et que tout le monde veut ajouter à son CV, est un domaine qui
regroupe tous les champs de l'analyse scientifique des données. Cela
demande donc, pour être fait sérieusement, de maîtriser~:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  un large champ de connaissances scientifiques, notamment des notions
  de statistiques appliquées~;
\item
  les données que vous manipulez~;
\item
  un langage de programmation pour automatiser les traitements.
\end{enumerate}

    \hypertarget{statistiques-appliquuxe9es}{%
\paragraph{Statistiques appliquées}\label{statistiques-appliquuxe9es}}

    Pour illustrer le premier point, pour quelque chose d'aussi simple
qu'une moyenne, il est déjà possible de faire des erreurs. Quel intérêt
de considérer une moyenne d'une distribution bimodale~?

Par exemple, j'ai deux groupes de personnes et je veux savoir lequel a
le plus de chance de gagner à une épreuve de tir à la corde. L'âge moyen
de mon groupe A est de 55 ans, l'âge moyen de mon groupe B est de 30
ans. Il me semble alors pouvoir affirmer que le groupe B a plus de
chances de gagner. Seulement, dans le groupe B il y a 10 enfants de 5
ans et 10 personnes de 55 ans et dans le groupe A j'ai une population
homogène de 20 personnes ayant 55 ans. Finalement, ça sera sans doute le
groupe A qui va gagner.

Quelle erreur ai-je faite~? J'ai utilisé un outil statistique qui
n'était pas adapté à l'analyse de mes groupes de personnes. Cette erreur
peut vous paraître stupide, mais ces erreurs peuvent être très subtiles
voire extrêmement difficiles à identifier.

    \hypertarget{connaissance-des-donnuxe9es}{%
\paragraph{Connaissance des données}\label{connaissance-des-donnuxe9es}}

    C'est une des parties les plus importantes, mais largement sous
estimées~: analyser des données sur lesquelles on n'a pas d'expertise
est une aberration. Le risque principal est d'ignorer l'existence d'un
facteur caché, ou de supposer à tort l'indépendance des données (sachant
que nombre d'outils statistiques ne fonctionnent que sur des données
indépendantes). Sans rentrer plus dans le détail, je vous conseille de
lire cet article de
\href{https://sciencetonnante.wordpress.com/2013/04/29/le-paradoxe-de-simpson/}{David
Louapre sur le paradoxe de Simpson} et
\href{https://www.youtube.com/watch?v=vs_Zzf_vL2I}{la vidéo associée},
pour vous donner l'intuition que travailler sur des données qu'on ne
maîtrise pas peut conduire à d'importantes erreurs d'interprétation.

    \hypertarget{mauxeetrise-dun-langage-de-programmation}{%
\paragraph{Maîtrise d'un langage de
programmation}\label{mauxeetrise-dun-langage-de-programmation}}

    Comme vous l'avez sans doute compris, le succès grandissant de la data
science est dû à la démocratisation d'outils informatiques comme R, ou
la suite d'outils disponibles dans Python, dont nous abordons certains
aspects cette semaine.

Il y a ici cependant de nouveau des difficultés. Comme nous allons le
voir il est très facile de faire des erreurs qui seront totalement
silencieuses, par conséquent, vous obtiendrez presque toujours un
résultat, mais totalement faux. Sans une profonde compréhension des
mécanismes et des implémentations, vous avez la garantie de faire
n'importe quoi.

Vous le voyez, je ne suis pas très encourageant, pour faire de la data
science vous devrez maîtriser la bases des outils statistiques,
comprendre les données que vous manipulez et maîtriser parfaitement les
outils que vous utilisez. Beaucoup de gens pensent qu'en faisant un peu
de R ou de Python on peut s'affirmer data scientist, c'est faux, et si
vous êtes, par exemple, journaliste ou économiste et que vos résultats
ont un impact politique, vous avez une vraie responsabilité et vos
erreurs peuvent avoir d'importantes conséquences.

    \hypertarget{pruxe9sentation-de-pandas}{%
\subsubsection{\texorpdfstring{Présentation de
\texttt{pandas}}{Présentation de pandas}}\label{pruxe9sentation-de-pandas}}

    \texttt{numpy} est l'outil qui permet de manipuler des tableaux en
Python, et \texttt{pandas} est l'outil qui permet d'ajouter des index à
ces tableaux. Par conséquent, \texttt{pandas} repose entièrement sur
\texttt{numpy} et toutes les données que vous manipulez en
\texttt{pandas} sont des tableaux \texttt{numpy}.

\texttt{pandas} est un projet qui évolue régulièrement, on vous
recommande donc d'utiliser au moins \texttt{pandas} dans sa version
0.21. Voici les versions que l'on utilise ici.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{numpy version }\PY{l+s+si}{\PYZob{}np.\PYZus{}\PYZus{}version\PYZus{}\PYZus{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pandas version }\PY{l+s+si}{\PYZob{}pd.\PYZus{}\PYZus{}version\PYZus{}\PYZus{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
numpy version 1.14.5
pandas version 0.23.3

    \end{Verbatim}

    Il est important de comprendre que le monde de la data science en Python
suit un autre paradigme que Python. Là où Python favorise la clarté, la
simplicité et l'uniformité, \texttt{numpy} and \texttt{pandas}
favorisent l'efficacité. La conséquence est une augmentation de la
complexité et une moins bonne uniformité. Aussi, personne ne joue le
rôle de BDFL dans la communauté data science comme le fait Guido van
Rossum pour Python. Nous entrons donc largement dans une autre
philosophie que celle de Python.

    \hypertarget{les-structures-de-donnuxe9es-en-pandas}{%
\paragraph{\texorpdfstring{Les structures de données en
\texttt{pandas}}{Les structures de données en pandas}}\label{les-structures-de-donnuxe9es-en-pandas}}

    Il y a deux structures de données principales en \texttt{pandas}, la
classe \texttt{Series} et la classe \texttt{DataFrame}. Une
\texttt{Series} est un tableau à une dimension où chaque élément est
indexé avec essentiellement un autre array (souvent de chaînes de
caractères), et une \texttt{DataFrame} est un tableau à deux dimensions
où les lignes et les colonnes sont indexées. La clef ici est de
comprendre que l'intérêt de \texttt{pandas} est de pouvoir manipuler les
tableaux \texttt{numpy} qui sont indexés, et le travail de
\texttt{pandas} est de rendre les opérations sur ces index très
efficaces.

    Vous pouvez bien sûr vous demander à quoi cela sert, alors regardons un
petit exemple. Nous allons revenir sur les notions utilisées dans cet
exemple, notre but ici est de vous montrer l'utilité de \texttt{pandas}
sur un exemple.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} seaborn est un module pour dessiner des courbes qui améliore}
        \PY{c+c1}{\PYZsh{} sensiblement matplotlib, mais ça n\PYZsq{}est pas ce qui nous intéresse ici.}
        \PY{c+c1}{\PYZsh{} seaborn vient avec quelques jeux de données sur lesquels on peut jouer.}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
        
        \PY{c+c1}{\PYZsh{} chargeons un jeu de données qui représente des pourboires}
        \PY{n}{tips} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tips}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \texttt{load\_dataset} retourne une \texttt{DataFrame}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n+nb}{type}\PY{p}{(}\PY{n}{tips}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:} pandas.core.frame.DataFrame
\end{Verbatim}
            
    Regardons maintenant à quoi ressemble une \texttt{DataFrame}~:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} voici à quoi ressemblent ces données. On a la note totale (total\PYZus{}bill),}
        \PY{c+c1}{\PYZsh{} le pourboire (tip), le sexe de la personne qui a donné le pourboire,}
        \PY{c+c1}{\PYZsh{} si la personne est fumeur ou non fumeur (smoker), le jour du repas,}
        \PY{c+c1}{\PYZsh{} le moment du repas (time) et le nombre de personnes à table (size)}
        \PY{n}{tips}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:}    total\_bill   tip     sex smoker  day    time  size
        0       16.99  1.01  Female     No  Sun  Dinner     2
        1       10.34  1.66    Male     No  Sun  Dinner     3
        2       21.01  3.50    Male     No  Sun  Dinner     3
        3       23.68  3.31    Male     No  Sun  Dinner     2
        4       24.59  3.61  Female     No  Sun  Dinner     4
\end{Verbatim}
            
    On voit donc un exemple de \texttt{DataFrame} qui représente des données
indexées, à la fois par des labels sur les colonnes, et par un rang
entier sur les lignes. C'est l'utilisation de ces index qui va nous
permettre de faire des requêtes expressives sur ces données.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} commençons par une rapide description statistique de ces données}
        \PY{n}{tips}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:}        total\_bill         tip        size
        count  244.000000  244.000000  244.000000
        mean    19.785943    2.998279    2.569672
        std      8.902412    1.383638    0.951100
        min      3.070000    1.000000    1.000000
        25\%     13.347500    2.000000    2.000000
        50\%     17.795000    2.900000    2.000000
        75\%     24.127500    3.562500    3.000000
        max     50.810000   10.000000    6.000000
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} prenons la moyenne par sexe}
        \PY{n}{tips}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:}         total\_bill       tip      size
        sex                                   
        Male     20.744076  3.089618  2.630573
        Female   18.056897  2.833448  2.459770
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} et maintenant la moyenne par jour}
        \PY{n}{tips}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:}       total\_bill       tip      size
        day                                 
        Thur   17.682742  2.771452  2.451613
        Fri    17.151579  2.734737  2.105263
        Sat    20.441379  2.993103  2.517241
        Sun    21.410000  3.255132  2.842105
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} et pour finir la moyenne par moment du repas}
        \PY{n}{tips}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:}         total\_bill       tip      size
        time                                  
        Lunch    17.168676  2.728088  2.411765
        Dinner   20.797159  3.102670  2.630682
\end{Verbatim}
            
    Vous voyez qu'en quelques requêtes simples et intuitives (nous
reviendrons bien sûr sur ces notions) on peut grâce à la notion d'index,
obtenir des informations précieuses sur nos données. Vous voyez qu'en
l'occurrence, travailler directement sur le tableau \texttt{numpy}
aurait été beaucoup moins aisé.

    \hypertarget{conclusion}{%
\subsubsection{Conclusion}\label{conclusion}}

    Nous avons vu que la data science est une discipline complexe qui
demande de nombreuses compétences. Une de ces compétences est la
maîtrise d'un langage de programmation, et à cet égard la suite data
science de Python qui se base sur \texttt{numpy} et \texttt{pandas}
offre une solution très performante.

    Il nous reste une dernière question à aborder~: R ou la suite data
science de Python~?

Notre préférence va bien évidemment à la suite data science de Python
parce qu'elle bénéficie de toute la puissance de Python. R est un
langage dédié à la statistique qui n'offre pas la puissance d'un langage
générique comme Python. Mais dans le contexte de la data science, R et
la suite data science de Python sont deux excellentes solutions. À très
grosse maille, la syntaxe de R est plus complexe que celle de Python,
par contre, R est très utilisé par les statisticiens, il peut donc avoir
une implémentation d'un nouvel algorithme de l'état de l'art plus
rapidement que la suite data science de Python.


    % Add a bibliography block to the postdoc
    
    
    
